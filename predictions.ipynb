{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotel booking\n",
    "\n",
    "### Predicting cancelations\n",
    "It would be nice for the hotels to have a model to predict if a guest will actually come.  \n",
    "This can help a hotel to plan things like personel and food requirements.  \n",
    "Maybe some hotels also use such a model to offer more rooms than they have to make more money... who knows..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup, data inspection and cleanup are hidden for easier reading. Click the Code/Output buttons if you are curious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: eli5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.13.0)\n",
      "Requirement already satisfied: attrs>17.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from eli5) (23.2.0)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from eli5) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/codespace/.local/lib/python3.10/site-packages (from eli5) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from eli5) (1.13.1)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from eli5) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /home/codespace/.local/lib/python3.10/site-packages (from eli5) (1.5.0)\n",
      "Requirement already satisfied: graphviz in /usr/local/python/3.10.13/lib/python3.10/site-packages (from eli5) (0.20.3)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from eli5) (0.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2>=3.0.0->eli5) (2.1.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20->eli5) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20->eli5) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11735/914732604.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  full_data_cln[\"meal\"].replace(\"Undefined\", \"SC\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "!pip install xgboost\n",
    "!pip install eli5\n",
    "\n",
    "# common:\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import folium\n",
    "\n",
    "# for ML:\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# set some display options:\n",
    "sns.set(style=\"whitegrid\")\n",
    "pd.set_option(\"display.max_columns\", 36)\n",
    "\n",
    "# load data:\n",
    "file_path = \"hotel_bookings.csv\"\n",
    "full_data = pd.read_csv(file_path)\n",
    "\n",
    "# Replace missing values:\n",
    "# agent: If no agency is given, booking was most likely made without one.\n",
    "# company: If none given, it was most likely private.\n",
    "# rest schould be self-explanatory.\n",
    "nan_replacements = {\"children:\": 0.0,\"country\": \"Unknown\", \"agent\": 0, \"company\": 0}\n",
    "full_data_cln = full_data.fillna(nan_replacements)\n",
    "\n",
    "# \"meal\" contains values \"Undefined\", which is equal to SC.\n",
    "full_data_cln[\"meal\"].replace(\"Undefined\", \"SC\", inplace=True)\n",
    "\n",
    "# Some rows contain entreis with 0 adults, 0 children and 0 babies. \n",
    "# We are dropping these entries with no guests.\n",
    "zero_guests = list(full_data_cln.loc[full_data_cln[\"adults\"]\n",
    "                   + full_data_cln[\"children\"]\n",
    "                   + full_data_cln[\"babies\"]==0].index)\n",
    "full_data_cln.drop(full_data_cln.index[zero_guests], inplace=True)\n",
    "\n",
    "full_data_cln.shape\n",
    "\n",
    "rh = full_data_cln.loc[(full_data_cln[\"hotel\"] == \"Resort Hotel\") & (full_data_cln[\"is_canceled\"] == 0)]\n",
    "ch = full_data_cln.loc[(full_data_cln[\"hotel\"] == \"City Hotel\") & (full_data_cln[\"is_canceled\"] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predict cancelations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which numerical features are most important? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_time                         0.293123\n",
       "total_of_special_requests         0.234658\n",
       "required_car_parking_spaces       0.195498\n",
       "booking_changes                   0.144381\n",
       "previous_cancellations            0.110133\n",
       "is_repeated_guest                 0.084793\n",
       "agent                             0.083114\n",
       "adults                            0.060017\n",
       "previous_bookings_not_canceled    0.057358\n",
       "days_in_waiting_list              0.054186\n",
       "adr                               0.047557\n",
       "babies                            0.032491\n",
       "stays_in_week_nights              0.024765\n",
       "company                           0.020642\n",
       "arrival_date_year                 0.016660\n",
       "arrival_date_week_number          0.008148\n",
       "arrival_date_day_of_month         0.006130\n",
       "children                          0.005048\n",
       "stays_in_weekend_nights           0.001791\n",
       "Name: is_canceled, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancel_corr = full_data.corr(numeric_only = True)[\"is_canceled\"]\n",
    "cancel_corr.abs().sort_values(ascending=False)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_time                         0.293123\n",
       "total_of_special_requests         0.234658\n",
       "required_car_parking_spaces       0.195498\n",
       "booking_changes                   0.144381\n",
       "previous_cancellations            0.110133\n",
       "is_repeated_guest                 0.084793\n",
       "agent                             0.083114\n",
       "adults                            0.060017\n",
       "previous_bookings_not_canceled    0.057358\n",
       "days_in_waiting_list              0.054186\n",
       "adr                               0.047557\n",
       "babies                            0.032491\n",
       "stays_in_week_nights              0.024765\n",
       "company                           0.020642\n",
       "arrival_date_year                 0.016660\n",
       "arrival_date_week_number          0.008148\n",
       "arrival_date_day_of_month         0.006130\n",
       "children                          0.005048\n",
       "stays_in_weekend_nights           0.001791\n",
       "Name: is_canceled, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancel_corr = full_data.corr(numeric_only = True)[\"is_canceled\"]\n",
    "cancel_corr.abs().sort_values(ascending=False)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list it is apparent that lead_time, total_of_special_requests, required_car_parking_spaces, booking_changes and previous_cancellations are the 5 most important numerical features.  \n",
    "However, to predict wheater or not a booking will be canceled, the number of booking changes is a possible source of leakage, because this information can change over time.  \n",
    "I will also not include days_in_waiting_list and arrival_date_year.  \n",
    "  \n",
    "The most important feature to exclude is the \"reservation_status\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_canceled  reservation_status\n",
       "0            Check-Out             75166\n",
       "1            Canceled              43017\n",
       "             No-Show                1207\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.groupby(\"is_canceled\")[\"reservation_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing different base models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually choose columns to include\n",
    "# some columns are excluded to make the model more general and to prevent leakage\n",
    "# (arrival_date_year, assigned_room_type, booking_changes, reservation_status, country,\n",
    "# days_in_waiting_list)\n",
    "# including the country would increase accuracy, but it may also make the model less general\n",
    "\n",
    "num_features = [\"lead_time\",\"arrival_date_week_number\",\"arrival_date_day_of_month\",\n",
    "                \"stays_in_weekend_nights\",\"stays_in_week_nights\",\"adults\",\"children\",\n",
    "                \"babies\",\"is_repeated_guest\", \"previous_cancellations\",\n",
    "                \"previous_bookings_not_canceled\",\"agent\",\"company\",\n",
    "                \"required_car_parking_spaces\", \"total_of_special_requests\", \"adr\"]\n",
    "\n",
    "cat_features = [\"hotel\",\"arrival_date_month\",\"meal\",\"market_segment\",\n",
    "                \"distribution_channel\",\"reserved_room_type\",\"deposit_type\",\"customer_type\"]\n",
    "\n",
    "# Separate features and predicted value\n",
    "features = num_features + cat_features\n",
    "X = full_data.drop([\"is_canceled\"], axis=1)[features]\n",
    "y = full_data[\"is_canceled\"]\n",
    "\n",
    "# preprocess numerical feats:\n",
    "# for most num cols, except the dates, 0 is the most logical choice as fill value\n",
    "# and here no dates are missing.\n",
    "num_transformer = SimpleImputer(strategy=\"constant\")\n",
    "\n",
    "# Preprocessing for categorical features:\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical features:\n",
    "preprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, num_features),\n",
    "                                               (\"cat\", cat_transformer, cat_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT_model cross validation accuarcy score: 0.8246 +/- 0.0016 (std) min: 0.8221, max: 0.8263\n",
      "RF_model cross validation accuarcy score: 0.8664 +/- 0.0012 (std) min: 0.8646, max: 0.8676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_model cross validation accuarcy score: 0.7935 +/- 0.0013 (std) min: 0.7915, max: 0.7951\n",
      "XGB_model cross validation accuarcy score: 0.8456 +/- 0.0004 (std) min: 0.8451, max: 0.8461\n"
     ]
    }
   ],
   "source": [
    "# define models to test:\n",
    "base_models = [(\"DT_model\", DecisionTreeClassifier(random_state=42)),\n",
    "               (\"RF_model\", RandomForestClassifier(random_state=42,n_jobs=-1)),\n",
    "               (\"LR_model\", LogisticRegression(random_state=42,n_jobs=-1)),\n",
    "               (\"XGB_model\", XGBClassifier(random_state=42, n_jobs=-1))]\n",
    "\n",
    "# split data into 'kfolds' parts for cross validation,\n",
    "# use shuffle to ensure random distribution of data:\n",
    "kfolds = 4 # 4 = 75% train, 25% validation\n",
    "split = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "\n",
    "# Preprocessing, fitting, making predictions and scoring for every model:\n",
    "for name, model in base_models:\n",
    "    # pack preprocessing of data and the model in a pipeline:\n",
    "    model_steps = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)])\n",
    "    \n",
    "    # get cross validation score for each model:\n",
    "    cv_results = cross_val_score(model_steps, \n",
    "                                 X, y, \n",
    "                                 cv=split,\n",
    "                                 scoring=\"accuracy\",\n",
    "                                 n_jobs=-1)\n",
    "    # output:\n",
    "    min_score = round(min(cv_results), 4)\n",
    "    max_score = round(max(cv_results), 4)\n",
    "    mean_score = round(np.mean(cv_results), 4)\n",
    "    std_dev = round(np.std(cv_results), 4)\n",
    "    print(f\"{name} cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")\n",
    "    \n",
    "    #pipeline.fit(X_train, y_train)\n",
    "    #preds = pipeline.predict(X_valid)\n",
    "    #score = accuracy_score(y_valid, preds)\n",
    "    #print(f\"{name} accuracy_score: {round(score, 4)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForst model performs best.  \n",
    "I also did some hyperparameter optimization, but the accuracy increase is minimal:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced RF model cross validation accuarcy score: 0.8681 +/- 0.0006 (std) min: 0.8673, max: 0.869\n"
     ]
    }
   ],
   "source": [
    "# Enhanced RF model with the best parameters I found:\n",
    "rf_model_enh = RandomForestClassifier(n_estimators=160,\n",
    "                               max_features=0.4,\n",
    "                               min_samples_split=2,\n",
    "                               n_jobs=-1,\n",
    "                               random_state=0)\n",
    "\n",
    "split = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "model_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', rf_model_enh)])\n",
    "cv_results = cross_val_score(model_pipe, \n",
    "                                 X, y, \n",
    "                                 cv=split,\n",
    "                                 scoring=\"accuracy\",\n",
    "                                 n_jobs=-1)\n",
    "# output:\n",
    "min_score = round(min(cv_results), 4)\n",
    "max_score = round(max(cv_results), 4)\n",
    "mean_score = round(np.mean(cv_results), 4)\n",
    "std_dev = round(np.std(cv_results), 4)\n",
    "print(f\"Enhanced RF model cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
